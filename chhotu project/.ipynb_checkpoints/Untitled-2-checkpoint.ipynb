{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('spam.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>make</th>\n",
       "      <th>address</th>\n",
       "      <th>all</th>\n",
       "      <th>3d</th>\n",
       "      <th>our</th>\n",
       "      <th>over</th>\n",
       "      <th>remove</th>\n",
       "      <th>internet</th>\n",
       "      <th>order</th>\n",
       "      <th>mail</th>\n",
       "      <th>...</th>\n",
       "      <th>semicol</th>\n",
       "      <th>paren</th>\n",
       "      <th>bracket</th>\n",
       "      <th>bang</th>\n",
       "      <th>dollar</th>\n",
       "      <th>pound</th>\n",
       "      <th>cap_avg</th>\n",
       "      <th>cap_long</th>\n",
       "      <th>cap_total</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.666</td>\n",
       "      <td>10</td>\n",
       "      <td>180</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.46</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.510</td>\n",
       "      <td>10</td>\n",
       "      <td>74</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.718</td>\n",
       "      <td>11</td>\n",
       "      <td>55</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.33</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.11</td>\n",
       "      <td>3.426</td>\n",
       "      <td>72</td>\n",
       "      <td>819</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>2.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.428</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.98</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.81</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.617</td>\n",
       "      <td>18</td>\n",
       "      <td>131</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.982</td>\n",
       "      <td>28</td>\n",
       "      <td>167</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.228</td>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.377</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.925</td>\n",
       "      <td>27</td>\n",
       "      <td>158</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.333</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>...</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.455</td>\n",
       "      <td>24</td>\n",
       "      <td>387</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.666</td>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.78</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.541</td>\n",
       "      <td>5</td>\n",
       "      <td>37</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.225</td>\n",
       "      <td>22</td>\n",
       "      <td>129</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.428</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.588</td>\n",
       "      <td>15</td>\n",
       "      <td>277</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.133</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.200</td>\n",
       "      <td>6</td>\n",
       "      <td>114</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.39</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.069</td>\n",
       "      <td>13</td>\n",
       "      <td>89</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.26</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.414</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.955</td>\n",
       "      <td>65</td>\n",
       "      <td>667</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    make  address   all   3d   our  over  remove  internet  order  mail  ...  \\\n",
       "0   0.00     0.00  0.29  0.0  0.00  0.00    0.00      0.00   0.00  0.00  ...   \n",
       "1   0.46     0.00  0.00  0.0  0.00  0.00    0.00      0.00   0.00  0.00  ...   \n",
       "2   0.00     0.00  0.00  0.0  0.00  0.00    0.00      0.00   0.00  0.00  ...   \n",
       "3   0.33     0.44  0.37  0.0  0.14  0.11    0.00      0.07   0.97  1.16  ...   \n",
       "4   0.00     2.08  0.00  0.0  3.12  0.00    1.04      0.00   0.00  0.00  ...   \n",
       "5   0.00     0.00  0.27  0.0  0.81  0.81    0.00      2.98   0.54  0.81  ...   \n",
       "6   0.00     0.46  0.00  0.0  0.00  0.00    0.00      0.00   0.00  0.00  ...   \n",
       "7   0.00     0.00  0.00  0.0  0.00  0.00    0.00      0.00   0.00  0.00  ...   \n",
       "8   0.00     0.00  0.00  0.0  0.00  0.00    0.00      0.00   0.00  0.00  ...   \n",
       "9   0.00     0.00  0.00  0.0  0.00  0.00    0.00      0.00   0.00  0.00  ...   \n",
       "10  0.37     0.18  0.18  0.0  0.37  0.00    0.00      0.18   0.00  0.18  ...   \n",
       "11  0.00     0.00  0.00  0.0  0.00  0.00    0.00      0.00   0.00  0.00  ...   \n",
       "12  0.00     0.00  1.33  0.0  1.78  0.44    0.00      0.44   0.00  0.00  ...   \n",
       "13  0.90     0.00  0.00  0.0  0.00  0.00    0.00      0.00   0.00  0.00  ...   \n",
       "14  0.00     0.00  0.00  0.0  0.00  0.00    0.00      0.00   0.00  0.00  ...   \n",
       "15  0.00     0.00  0.00  0.0  0.20  0.00    0.00      0.00   0.00  0.00  ...   \n",
       "16  0.00     0.00  0.86  0.0  0.43  0.00    0.00      0.00   0.00  0.00  ...   \n",
       "17  0.39     0.00  0.00  0.0  1.17  0.00    0.00      0.00   0.00  0.39  ...   \n",
       "18  0.00     0.00  0.00  0.0  0.00  0.00    0.00      0.00   0.00  0.00  ...   \n",
       "19  0.66     0.00  0.26  0.0  0.26  0.00    0.13      0.00   0.66  0.26  ...   \n",
       "\n",
       "    semicol  paren  bracket   bang  dollar  pound  cap_avg  cap_long  \\\n",
       "0     0.000  0.178    0.000  0.044   0.000   0.00    1.666        10   \n",
       "1     0.000  0.125    0.000  0.000   0.000   0.00    1.510        10   \n",
       "2     0.000  0.000    0.000  0.000   0.000   0.00    1.718        11   \n",
       "3     0.006  0.159    0.000  0.069   0.221   0.11    3.426        72   \n",
       "4     0.000  0.000    0.000  0.263   0.000   0.00    1.428         4   \n",
       "5     0.000  0.040    0.000  0.565   0.121   0.00    1.617        18   \n",
       "6     0.000  0.155    0.000  0.000   0.000   0.00    2.982        28   \n",
       "7     0.000  0.000    0.138  0.000   0.000   0.00    1.228         4   \n",
       "8     0.000  0.377    0.000  0.125   0.000   0.00    2.925        27   \n",
       "9     0.000  0.000    0.000  0.000   0.000   0.00    4.333        11   \n",
       "10    0.116  0.290    0.029  0.029   0.029   0.00    3.455        24   \n",
       "11    0.000  0.000    0.000  0.000   0.000   0.00    1.666         9   \n",
       "12    0.078  0.078    0.000  0.000   0.000   0.00    1.541         5   \n",
       "13    0.000  0.150    0.000  0.000   0.000   0.00    3.225        22   \n",
       "14    0.000  0.000    0.000  0.000   0.000   0.00    1.428         3   \n",
       "15    0.000  0.204    0.000  0.034   0.000   0.00    2.588        15   \n",
       "16    0.000  0.161    0.000  1.133   0.000   0.00    1.200         6   \n",
       "17    0.070  0.070    0.000  0.070   0.000   0.00    2.069        13   \n",
       "18    0.000  0.000    0.000  0.000   0.000   0.00    1.000         1   \n",
       "19    0.000  0.109    0.000  0.414   0.021   0.00    5.955        65   \n",
       "\n",
       "    cap_total  Class  \n",
       "0         180    ham  \n",
       "1          74    ham  \n",
       "2          55    ham  \n",
       "3         819   spam  \n",
       "4          20   spam  \n",
       "5         131   spam  \n",
       "6         167    ham  \n",
       "7          43    ham  \n",
       "8         158    ham  \n",
       "9          13    ham  \n",
       "10        387    ham  \n",
       "11         25    ham  \n",
       "12         37   spam  \n",
       "13        129    ham  \n",
       "14         10    ham  \n",
       "15        277   spam  \n",
       "16        114   spam  \n",
       "17         89    ham  \n",
       "18          9    ham  \n",
       "19        667   spam  \n",
       "\n",
       "[20 rows x 58 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.drop(\"Class\",axis=1)\n",
    "label = df[\"Class\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, test_features, train_label, test_label = train_test_split(features, label, test_size = 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4601, 58)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1150,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1150,), (1150, 57))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label.shape, train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_clf = AdaBoostClassifier(DecisionTreeClassifier(),n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=100)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_clf.fit(train_features,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8924949290060852"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_clf.score(test_features, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vnpatel/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compared accuracy 0.9255288322225442\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.95      0.92      0.94      2124\n",
      "        spam       0.88      0.93      0.91      1327\n",
      "\n",
      "    accuracy                           0.93      3451\n",
      "   macro avg       0.92      0.93      0.92      3451\n",
      "weighted avg       0.93      0.93      0.93      3451\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_log = LogisticRegression( random_state=100)\n",
    "clf_rdf = RandomForestClassifier(n_estimators=50, random_state=100)\n",
    "clf_knn = KNeighborsClassifier(n_neighbors=8)\n",
    "ensemble_clf = VotingClassifier(estimators=[('logistic', clf_log), ('Random', clf_rdf), ('KNN', clf_knn)], voting='hard')\n",
    "ensemble_clf = ensemble_clf.fit(train_features,train_label)\n",
    "accuracy = ensemble_clf.score(test_features,test_label)\n",
    "print('compared accuracy' ,accuracy)\n",
    "test_predict = ensemble_clf.predict(test_features)\n",
    "confusion_matrix(test_predict, test_label)\n",
    "print(classification_report(test_predict, test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features Shape:\n",
      " (2300, 57)\n",
      "Training Labels Shape:\n",
      " (2300,)\n",
      "Testing Features Shape:\n",
      " (2301, 57)\n",
      "Testing Labels Shape:\n",
      " (2301,)\n",
      "Accuracy of AdaBoost Ensemble with Desicion tree as base learner 0.9426336375488917\n",
      "AdaBoost Decision Tree Confusion Matrix:\n",
      " [[1338   44]\n",
      " [  88  831]]\n",
      "AdaBoost Decision Tree Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.94      0.97      0.95      1382\n",
      "        spam       0.95      0.90      0.93       919\n",
      "\n",
      "    accuracy                           0.94      2301\n",
      "   macro avg       0.94      0.94      0.94      2301\n",
      "weighted avg       0.94      0.94      0.94      2301\n",
      "\n",
      "Training Features Shape:\n",
      " (2760, 57)\n",
      "Training Labels Shape:\n",
      " (2760,)\n",
      "Testing Features Shape:\n",
      " (1841, 57)\n",
      "Testing Labels Shape:\n",
      " (1841,)\n",
      "Accuracy of AdaBoost Ensemble with Desicion tree as base learner 0.951113525258012\n",
      "AdaBoost Decision Tree Confusion Matrix:\n",
      " [[1085   36]\n",
      " [  54  666]]\n",
      "AdaBoost Decision Tree Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.95      0.97      0.96      1121\n",
      "        spam       0.95      0.93      0.94       720\n",
      "\n",
      "    accuracy                           0.95      1841\n",
      "   macro avg       0.95      0.95      0.95      1841\n",
      "weighted avg       0.95      0.95      0.95      1841\n",
      "\n",
      "Training Features Shape:\n",
      " (3220, 57)\n",
      "Training Labels Shape:\n",
      " (3220,)\n",
      "Testing Features Shape:\n",
      " (1381, 57)\n",
      "Testing Labels Shape:\n",
      " (1381,)\n",
      "Accuracy of AdaBoost Ensemble with Desicion tree as base learner 0.9616220130340333\n",
      "AdaBoost Decision Tree Confusion Matrix:\n",
      " [[816  25]\n",
      " [ 28 512]]\n",
      "AdaBoost Decision Tree Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      0.97      0.97       841\n",
      "        spam       0.95      0.95      0.95       540\n",
      "\n",
      "    accuracy                           0.96      1381\n",
      "   macro avg       0.96      0.96      0.96      1381\n",
      "weighted avg       0.96      0.96      0.96      1381\n",
      "\n",
      "Training Features Shape:\n",
      " (3680, 57)\n",
      "Training Labels Shape:\n",
      " (3680,)\n",
      "Testing Features Shape:\n",
      " (921, 57)\n",
      "Testing Labels Shape:\n",
      " (921,)\n",
      "Accuracy of AdaBoost Ensemble with Desicion tree as base learner 0.9576547231270358\n",
      "AdaBoost Decision Tree Confusion Matrix:\n",
      " [[547  12]\n",
      " [ 27 335]]\n",
      "AdaBoost Decision Tree Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.95      0.98      0.97       559\n",
      "        spam       0.97      0.93      0.94       362\n",
      "\n",
      "    accuracy                           0.96       921\n",
      "   macro avg       0.96      0.95      0.96       921\n",
      "weighted avg       0.96      0.96      0.96       921\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "r1=[0.5,0.4,0.3,0.2]\n",
    "for i in r1:\n",
    "    train_features, test_features,train_label,test_label=train_test_split(features, label, test_size=i)\n",
    "    ada_clf = AdaBoostClassifier(DecisionTreeClassifier(),n_estimators=100)\n",
    "    ada_clf.fit(train_features, train_label)\n",
    "    accuracy_desicion = ada_clf.score(test_features, test_label)\n",
    "    predict_acc=ada_clf.predict(test_features)\n",
    "    accuracy_ada=accuracy_score(test_label,predict_acc)\n",
    "    conf_matrix=confusion_matrix(test_label,predict_acc)\n",
    "    class_report=classification_report(test_label,predict_acc)\n",
    "    print('Training Features Shape:\\n',train_features.shape)\n",
    "    print('Training Labels Shape:\\n',train_label.shape)\n",
    "    print('Testing Features Shape:\\n',test_features.shape)\n",
    "    print('Testing Labels Shape:\\n',test_label.shape)   \n",
    "    print('Accuracy of AdaBoost Ensemble with Desicion tree as base learner', accuracy_desicion)\n",
    "    print('AdaBoost Decision Tree Confusion Matrix:\\n',conf_matrix)    \n",
    "    print('AdaBoost Decision Tree Classification Report:\\n',class_report)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fbc768028c3e6ead51d9a200ddcb2ec858ae62844dcd1994729a8279be9b48f2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
