# -*- coding: utf-8 -*-
"""myFirst.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hmrAMntPVFW4QXsUcxNhbAMdPXEba1l1
"""

!pip install --upgrade tensorflow

from __future__ import print_function
import pandas as pd
pd.__version__

import os
os.getcwd()

#Mouting the drive to load a simple dataset stored on the google drive
from google.colab import drive
drive.mount('/content/gdrive')

#Loading a dataset into a dataframe
#Use describe(), info(), head() functions to get simple statistics and a description of the dataset 
iris_dataset_dataframe = pd.read_csv("/content/gdrive/My Drive/iris.data", sep = ',')
print('Dataset Loaded...')
iris_dataset_dataframe.describe()
#Use iris 
#iris_dataset_dataframe.iloc[0:3]

#Use iloc to acces each row, index starts at 0 
iris_dataset_dataframe.iloc[0:3]

#Plot per feature histogram. figsize = (width, height)
iris_dataset_dataframe.hist(bins=25,figsize=(15,10))

import numpy as np

#Define a function to create a training and test set.
#Takes dataframe and split ratio as input and outputs train and test datasets (dataframes)
def split_train_test(data,test_ratio):
  np.random.seed(42) # fix the seed if you want to generate the same
  shuffled_indices = np.random.permutation(len(data))
  test_set_size = int(len(data)*test_ratio)
  test_indices = shuffled_indices[:test_set_size]
  train_indices = shuffled_indices[test_set_size:]
  return data.iloc[train_indices], data.iloc[test_indices]

from sklearn.model_selection import train_test_split

#You can also use Scikit-Learn to create a training and test set.
#random_state parameter fixes the seed.
iris_training_set, iris_test_set = train_test_split(iris_dataset_dataframe, test_size=0.2,random_state=42)
#iris_dataset_dataframe.keys()
#iris_test_set.head()

iris_training_data, iris_training_target = iris_training_set[["f1","f2","f3","f4"]], iris_training_set["class"]
iris_test_data, iris_test_target = iris_test_set[["f1","f2","f3","f4"]], iris_test_set["class"]

iris_training_data.head()

#Create training and test datasets for Iris data
#iris_training_set, iris_test_set = split_train_test(iris_dataset_dataframe, 0.2)
#iris_test_set.head()
#iris_test_set.info()

#Scatter plot of training and test data
iris_training_set.plot(kind="scatter", x = "f1", y = "f2")
iris_test_set.plot(kind="scatter", x = "f1", y = "f2")

from sklearn.ensemble import RandomForestClassifier
from sklearn import tree
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.metrics import accuracy_score
#clf = RandomForestClassifier()
#clf = DecisionTreeClassifier(criterion = "entropy")
#clf = KNeighborsClassifier(n_neighbors=3)
#clf = AdaBoostClassifier(n_estimators = 200)
#LRI = LogisticRegression( )
#clf = AdaBoostClassifier(n_estimators = 200,base_estimator=LRI)
clf.fit(iris_training_data,iris_training_target)

iris_test_target_predict=clf.predict(iris_test_data)
#confusion_matrix(iris_test_target,iris_test_target_predict)
#classification_report(iris_test_target,iris_test_target_predict)
accuracy_score(iris_test_target,iris_test_target_predict)